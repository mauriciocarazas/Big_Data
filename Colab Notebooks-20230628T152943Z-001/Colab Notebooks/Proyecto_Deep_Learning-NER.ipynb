{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPM3XqdB/Obnh38tXpQzSov"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gohtYf2cb9FK"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import json\n","\n","# Cargar los archivos JSON que contienen los conjuntos de entrenamiento y prueba\n","with open('/content/ner_promed_train.json') as f:\n","    train_data = json.load(f)\n","\n","with open('/content/ner_promed_test.json') as f:\n","    test_data = json.load(f)\n","\n","# Preparar los datos\n","# Aquí deberás realizar el preprocesamiento necesario para convertir las etiquetas a índices numéricos,\n","# dividir los datos en oraciones y etiquetas, y crear el diccionario de vocabulario.\n","\n","# Ejemplo de preprocesamiento para convertir etiquetas a índices numéricos\n","label_to_index = {\n","    'O': 0,\n","    'B-Abreviatura': 1,\n","    'I-Abreviatura': 2,\n","    'B-Conditional': 3,\n","    'I-Conditional': 4,\n","    'B-Date': 5,\n","    'I-Date': 6,\n","    'B-Disease': 7,\n","    'I-Disease': 8,\n","    'B-Host': 9,\n","    'I-Host': 10,\n","    'B-Location': 11,\n","    'I-Location': 12,\n","    'B-Negation': 13,\n","    'I-Negation': 14,\n","    'B-Number_of_cases': 15,\n","    'I-Number_of_cases': 16,\n","    'B-Origin': 17,\n","    'I-Origin': 18,\n","    'B-Past': 19,\n","    'I-Past': 20,\n","    'B-Transmission_form': 21,\n","    'I-Transmission_form': 22,\n","    'B-Uncertainty': 23,\n","    'I-Uncertainty': 24,\n","    'B-negatesRel': 25,\n","    'I-negatesRel': 26,\n","    'B-speculatesNrCasesOfDis': 27,\n","    'I-speculatesNrCasesOfDis': 28,\n","    'B-speculatesRel': 29,\n","    'I-speculatesRel': 30,\n","    'B-speculatesTFDs': 31,\n","    'I-speculatesTFDs': 32\n","}\n","\n","# Obtener oraciones y etiquetas de los datos de entrenamiento\n","train_sentences = [data[\"sentence\"] for data in train_data]\n","train_labels = [data[\"labels\"] for data in train_data]\n","\n","# Convertir etiquetas a índices numéricos en los datos de entrenamiento\n","train_labels_indices = [[label_to_index[label] for label in labels] for labels in train_labels]\n","\n","# Crear el diccionario de vocabulario\n","vocab = set([token for sentence in train_sentences for token in sentence])\n","vocab_size = len(vocab)\n","word_to_index = {word: index for index, word in enumerate(vocab)}\n","\n","# Definir parámetros del modelo\n","embedding_dim = 100\n","hidden_dim = 128\n","output_dim = len(label_to_index)\n","\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import json\n","\n","# Cargar los archivos JSON que contienen los conjuntos de entrenamiento y prueba\n","train_file = '/content/ner_promed_train.json'\n","test_file = '/content/ner_promed_test.json'\n","\n","with open(train_file) as f:\n","    train_data = json.load(f)\n","\n","with open(test_file) as f:\n","    test_data = json.load(f)\n","\n","# Preparar los datos\n","label_to_index = {\n","    'O': 0,\n","    'B-Abreviatura': 1,\n","    'I-Abreviatura': 2,\n","    'B-Conditional': 3,\n","    'I-Conditional': 4,\n","    'B-Date': 5,\n","    'I-Date': 6,\n","    'B-Disease': 7,\n","    'I-Disease': 8,\n","    'B-Host': 9,\n","    'I-Host': 10,\n","    'B-Location': 11,\n","    'I-Location': 12,\n","    'B-Negation': 13,\n","    'I-Negation': 14,\n","    'B-Number_of_cases': 15,\n","    'I-Number_of_cases': 16,\n","    'B-Origin': 17,\n","    'I-Origin': 18,\n","    'B-Past': 19,\n","    'I-Past': 20,\n","    'B-Transmission_form': 21,\n","    'I-Transmission_form': 22,\n","    'B-Uncertainty': 23,\n","    'I-Uncertainty': 24,\n","    'B-negatesRel': 25,\n","    'I-negatesRel': 26,\n","    'B-speculatesNrCasesOfDis': 27,\n","    'I-speculatesNrCasesOfDis': 28,\n","    'B-speculatesRel': 29,\n","    'I-speculatesRel': 30,\n","    'B-speculatesTFDs': 31,\n","    'I-speculatesTFDs': 32\n","}\n","\n","def prepare_data(data):\n","    sentences = []\n","    labels = []\n","    for item in data[\"samples\"]:\n","        tokens = item[\"tokens\"]\n","        tags = item[\"tags\"]\n","        sentences.append(tokens)\n","        label_indices = [label_to_index[tag] for tag in tags]\n","        labels.append(label_indices)\n","    return sentences, labels\n","\n","\n","train_sentences, train_labels = prepare_data(train_data)\n","test_sentences, test_labels = prepare_data(test_data)\n","\n","\n","# Crear el diccionario de vocabulario\n","vocab = set([token for sentence in train_sentences for token in sentence])\n","vocab_size = len(vocab)\n","word_to_index = {word: index for index, word in enumerate(vocab)}\n","\n","# Función para convertir oraciones a secuencias de índices numéricos\n","def sentence_to_indices(sentence):\n","    return [word_to_index.get(word, 0) for word in sentence]\n","\n","\n","\n","#\n","#El error ValueError: expected sequence of length 679 at dim 1 (got 281)\n","#indica que las secuencias de entrada tienen longitudes diferentes.\n","#Esto puede ocurrir si las oraciones en el conjunto de prueba tienen\n","#longitudes distintas a las oraciones en el conjunto de entrenamiento.\n","#\n","#Para solucionar este problema, puedes aplicar el método de padding a\n","#las secuencias de entrada para que todas tengan la misma longitud.\n","#Esto se puede lograr utilizando la función torch.nn.utils.rnn.pad_sequence.\n","#\n","\n","\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# Convertir las oraciones a secuencias de índices numéricos\n","train_sentences_indices = [torch.tensor(sentence_to_indices(sentence), dtype=torch.long) for sentence in train_sentences]\n","test_sentences_indices = [torch.tensor(sentence_to_indices(sentence), dtype=torch.long) for sentence in test_sentences]\n","\n","# Aplicar padding a las secuencias de entrada\n","train_sentences_padded = pad_sequence(train_sentences_indices, batch_first=True)\n","test_sentences_padded = pad_sequence(test_sentences_indices, batch_first=True)\n","\n","# Convertir las secuencias de entrada a tensores\n","train_sentences_padded = torch.stack(train_sentences_padded)\n","test_sentences_padded = torch.stack(test_sentences_padded)\n","\n","\n","#En este código, pad_sequence toma una lista de tensores de secuencias\n","# y aplica padding para que todas tengan la misma longitud en la\n","# dimensión especificada (en este caso, la dimensión del lote,\n","#que se establece en batch_first=True).\n","\n","# Definir parámetros del modelo\n","embedding_dim = 100\n","hidden_dim = 128\n","output_dim = len(label_to_index)\n","\n","# Definir la arquitectura del modelo RNN en PyTorch\n","class RNNModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n","        super(RNNModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)\n","        output, _ = self.rnn(embedded)\n","        output = self.fc(output)\n","        return output\n","\n","# Instanciar el modelo\n","model = RNNModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n","\n","# Definir la función de pérdida y el optimizador\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Entrenamiento del modelo\n","num_epochs = 10\n","batch_size = 32\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0.0\n","\n","    for i in range(0, len(train_sentences_indices), batch_size):\n","        batch_sentences = train_sentences_indices[i:i+batch_size]\n","        batch_labels = train_labels[i:i+batch_size]\n","\n","        optimizer.zero_grad()\n","\n","        inputs = torch.tensor(batch_sentences, dtype=torch.long)\n","        labels = torch.tensor(batch_labels, dtype=torch.long)\n","\n","        outputs = model(inputs)\n","        outputs = outputs.view(-1, output_dim)\n","        labels = labels.view(-1)\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}')\n","\n","# Evaluación del modelo\n","model.eval()\n","total_correct = 0\n","total_samples = 0\n","\n","with torch.no_grad():\n","    for i in range(0, len(test_sentences_indices), batch_size):\n","        batch_sentences = test_sentences_indices[i:i+batch_size]\n","        batch_labels = test_labels[i:i+batch_size]\n","\n","        inputs = torch.tensor(batch_sentences, dtype=torch.long)\n","        labels = torch.tensor(batch_labels, dtype=torch.long)\n","\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, dim=-1)\n","\n","        total_samples += labels.size(0)\n","        total_correct += (predicted == labels).sum().item()\n","\n","accuracy = total_correct / total_samples\n","print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"kgGUCV18cMG2","executionInfo":{"status":"error","timestamp":1687477899923,"user_tz":300,"elapsed":428,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"8a559dcc-3602-424a-fe0c-fbef4dcbd951"},"execution_count":12,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-b09003bc7a11>\u001b[0m in \u001b[0;36m<cell line: 142>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"]}]}]}