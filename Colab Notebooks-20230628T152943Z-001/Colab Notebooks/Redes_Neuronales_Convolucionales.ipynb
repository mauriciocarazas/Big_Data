{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYbD7YNlg9ziaTbClBZpCs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"TFHJub01Pr2z","executionInfo":{"status":"ok","timestamp":1685057392990,"user_tz":300,"elapsed":6688,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}}},"outputs":[],"source":["import torch\n"]},{"cell_type":"code","source":["a = torch.Tensor([[1,2],[3,4]])\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MyeqE4yEPy2d","executionInfo":{"status":"ok","timestamp":1685057409846,"user_tz":300,"elapsed":438,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"6bca42ab-80b9-4770-9a69-74c54f5aa81d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2.],\n","        [3., 4.]])\n"]}]},{"cell_type":"code","source":["from torch.autograd import Variable\n","# The following variables will be differentiable\n","a = Variable(torch.Tensor([[1,2],[3,4]]), requires_grad=True)\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtYd4za6Pz2k","executionInfo":{"status":"ok","timestamp":1685057413161,"user_tz":300,"elapsed":427,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"4c56e14b-227c-4cf0-9b64-75c7c4c29cf6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2.],\n","        [3., 4.]], requires_grad=True)\n"]}]},{"cell_type":"code","source":["y = torch.sum(a**2)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvbxV6ZyP0yc","executionInfo":{"status":"ok","timestamp":1685057415410,"user_tz":300,"elapsed":2,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"a25f6f05-3476-4ecd-edec-7996ce6f77e6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(30., grad_fn=<SumBackward0>)\n"]}]},{"cell_type":"code","source":["y.backward() # compute gradients of y wrt a "],"metadata":{"id":"FmYHZH95P1mk","executionInfo":{"status":"ok","timestamp":1685057417734,"user_tz":300,"elapsed":2,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(a.grad)  # print dy/da_ij = 2*a_ij for a_11, a_12, a21, a22"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgVyYN6JP27k","executionInfo":{"status":"ok","timestamp":1685057420456,"user_tz":300,"elapsed":2,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"1e0044ef-2daa-4bbd-cfce-85784238f877"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[2., 4.],\n","        [6., 8.]])\n"]}]},{"cell_type":"code","source":["output_batch = model(train_batch)           # compute model output\n","loss = loss_fn(output_batch, labels_batch)  # calculate loss\n","\n","optimizer.zero_grad()  # clear previous gradients\n","loss.backward()        # compute gradients of all variables wrt loss\n","\n","optimizer.step() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"PLnrQzPTP4f8","executionInfo":{"status":"error","timestamp":1685057454187,"user_tz":300,"elapsed":3,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"d63b233a-1463-454c-b5e6-efff04b92d0f"},"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-7880860a7446>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# compute model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clear previous gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# compute gradients of all variables wrt loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"bvyir2eAQAZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TwoLayerNet(nn.Module):\n","    def __init__(self, D_in, H, D_out): # 100, 50, 10\n","        \"\"\"\n","        In the constructor we instantiate two nn.Linear modules and assign them as\n","        #member variables.\n","\n","        D_in: input dimension\n","        H: dimension of hidden layer\n","        D_out: output dimension\"\"\"\n","        super(TwoLayerNet, self).__init__()\n","        self.linear1 = nn.Linear(D_in, H) # W_1\n","        self.linear2 = nn.Linear(H, D_out) # W_2\n","\n","    def forward(self, x): # x (batch_size, D_in)\n","        \"\"\"In the forward function we accept a Variable of input data and we must \n","        return a Variable of output data. We can use Modules defined in the \n","        constructor as well as arbitrary operators on Variables.\"\"\"\n","        h_relu = F.relu(self.linear1(x))\n","        y_pred = self.linear2(h_relu)\n","        return y_pred  # return batch_size, D_out"],"metadata":{"id":"HPGDkW2GQA08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x(32, 100)*w_1(100, 50)= h__relu (32, 50)* w_2 (50, 10)->\n","y_pred (32, 10)"],"metadata":{"id":"HK24xqvpQCs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n"],"metadata":{"id":"iaCgiMkhQXlT","executionInfo":{"status":"ok","timestamp":1685057581788,"user_tz":300,"elapsed":1353,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["mnist = fetch_openml('mnist_784')\n","X = mnist.data\n","y = mnist.target\n","\n","# Convertir las etiquetas de cadena a números enteros\n","y = y.astype(np.int)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvLECAxuQavy","executionInfo":{"status":"ok","timestamp":1685057642117,"user_tz":300,"elapsed":57460,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"790da6b3-3635-42a0-ffef-f8b1cf70606d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n","<ipython-input-10-48326f567bcf>:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y = y.astype(np.int)\n"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"metadata":{"id":"MD8tJp1DQc27"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Escalar los valores de píxeles al rango [0, 1]\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n"],"metadata":{"id":"eUSnUM5GQeK7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Perceptron:\n","    def __init__(self, lr=0.1, num_epochs=100):\n","        self.lr = lr\n","        self.num_epochs = num_epochs\n","\n","    def train(self, X, y):\n","        self.weights = np.zeros(X.shape[1])\n","        self.bias = 0\n","\n","        for epoch in range(self.num_epochs):\n","            for i in range(X.shape[0]):\n","                y_pred = self.predict(X[i])\n","                error = y[i] - y_pred\n","                self.weights += self.lr * error * X[i]\n","                self.bias += self.lr * error\n","\n","    def predict(self, X):\n","        linear_output = np.dot(X, self.weights) + self.bias\n","        activation = np.where(linear_output >= 0, 1, 0)\n","        return activation\n"],"metadata":{"id":"qdthJB4-QfXj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["perceptron = Perceptron(lr=0.1, num_epochs=10)\n","perceptron.train(X_train, y_train)\n","\n","y_pred_train = perceptron.predict(X_train)\n","y_pred_test = perceptron.predict(X_test)\n","\n","accuracy_train = accuracy_score(y_train, y_pred_train)\n","accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","print(\"Accuracy en el conjunto de entrenamiento:\", accuracy_train)\n","print(\"Accuracy en el conjunto de prueba:\", accuracy_test)\n"],"metadata":{"id":"7BnGuchqQgVS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import tensorflow as tf\n","from tensorflow.keras import models, layers\n","\n","mnist = fetch_openml('mnist_784')\n","X = mnist.data\n","y = mnist.target\n","\n","# Convertir las etiquetas de cadena a números enteros\n","y = y.astype(np.int)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","\n","# Escalar los valores de píxeles al rango [0, 1]\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu', input_shape=(784,)))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu', input_shape=(784,)))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","\n","accuracy_train = history.history['accuracy'][-1]\n","accuracy_test = history.history['val_accuracy'][-1]\n","\n","print(\"Accuracy en el conjunto de entrenamiento:\", accuracy_train)\n","print(\"Accuracy en el conjunto de prueba:\", accuracy_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UEHSbgbrQyAg","executionInfo":{"status":"ok","timestamp":1685057817758,"user_tz":300,"elapsed":134272,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"67d57edc-6987-445d-8773-bf2759fa5fe7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n","<ipython-input-11-e3ed20c025df>:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y = y.astype(np.int)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1750/1750 [==============================] - 7s 4ms/step - loss: 0.2790 - accuracy: 0.9184 - val_loss: 0.1732 - val_accuracy: 0.9486\n","Epoch 2/10\n","1750/1750 [==============================] - 7s 4ms/step - loss: 0.1252 - accuracy: 0.9621 - val_loss: 0.1214 - val_accuracy: 0.9636\n","Epoch 3/10\n","1750/1750 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9720 - val_loss: 0.1083 - val_accuracy: 0.9664\n","Epoch 4/10\n","1750/1750 [==============================] - 7s 4ms/step - loss: 0.0729 - accuracy: 0.9769 - val_loss: 0.1060 - val_accuracy: 0.9695\n","Epoch 5/10\n","1750/1750 [==============================] - 7s 4ms/step - loss: 0.0574 - accuracy: 0.9817 - val_loss: 0.0965 - val_accuracy: 0.9711\n","Epoch 6/10\n","1750/1750 [==============================] - 7s 4ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.0974 - val_accuracy: 0.9719\n","Epoch 7/10\n","1750/1750 [==============================] - 6s 3ms/step - loss: 0.0404 - accuracy: 0.9869 - val_loss: 0.0975 - val_accuracy: 0.9743\n","Epoch 8/10\n","1750/1750 [==============================] - 7s 4ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.0968 - val_accuracy: 0.9733\n","Epoch 9/10\n","1750/1750 [==============================] - 6s 4ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.0980 - val_accuracy: 0.9744\n","Epoch 10/10\n","1750/1750 [==============================] - 7s 4ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.1082 - val_accuracy: 0.9737\n","Accuracy en el conjunto de entrenamiento: 0.9915714263916016\n","Accuracy en el conjunto de prueba: 0.973714292049408\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.utils import to_categorical\n","\n","# Cargar los datos del conjunto MNIST\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Escalar los valores de píxeles al rango [0, 1]\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","# Aplanar las imágenes\n","X_train = X_train.reshape((X_train.shape[0], -1))\n","X_test = X_test.reshape((X_test.shape[0], -1))\n","\n","# Convertir las etiquetas a one-hot encoding\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# Construir el modelo del MLP\n","model = Sequential()\n","model.add(Dense(64, activation='relu', input_shape=(784,)))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Entrenar el modelo\n","history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","\n","# Evaluar el modelo en el conjunto de prueba\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sr0k3BHsSCOo","executionInfo":{"status":"ok","timestamp":1685058074657,"user_tz":300,"elapsed":86367,"user":{"displayName":"Mauricio Carazas Segovia","userId":"16643684742312453223"}},"outputId":"892bb762-1319-4c1c-baed-8cde750fde96"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n","Epoch 1/10\n","1875/1875 [==============================] - 7s 3ms/step - loss: 0.2737 - accuracy: 0.9205 - val_loss: 0.1437 - val_accuracy: 0.9568\n","Epoch 2/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1230 - accuracy: 0.9634 - val_loss: 0.0952 - val_accuracy: 0.9700\n","Epoch 3/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0908 - accuracy: 0.9721 - val_loss: 0.0897 - val_accuracy: 0.9725\n","Epoch 4/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0709 - accuracy: 0.9774 - val_loss: 0.0898 - val_accuracy: 0.9732\n","Epoch 5/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0595 - accuracy: 0.9815 - val_loss: 0.0803 - val_accuracy: 0.9738\n","Epoch 6/10\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.0492 - accuracy: 0.9841 - val_loss: 0.0983 - val_accuracy: 0.9704\n","Epoch 7/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0865 - val_accuracy: 0.9758\n","Epoch 8/10\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.0365 - accuracy: 0.9877 - val_loss: 0.0877 - val_accuracy: 0.9752\n","Epoch 9/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0313 - accuracy: 0.9891 - val_loss: 0.0963 - val_accuracy: 0.9751\n","Epoch 10/10\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.1103 - val_accuracy: 0.9713\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1103 - accuracy: 0.9713\n","Loss: 0.1103229746222496\n","Accuracy: 0.9713000059127808\n"]}]}]}